{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLayer Tutorial\n",
    "\n",
    "This tutorial gives you a brief insight in the functionalities offered by the `nn.SLayer` \n",
    "module. It assumes familarity with standard `PyTorch` functionality. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chofer_torchex.nn import SLayer\n",
    "\n",
    "#create an instance with 3 structure elements over \\R^2\n",
    "sl = SLayer(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.SLayer` is a `torch.nn.Module` ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "isinstance(sl, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... hence we can do all the beautiful stuff which is inherited from `torch.nn.Module`, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.6257  0.8112\n",
      " 0.9240  0.4342\n",
      " 0.9956  0.3554\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "Parameter containing:\n",
      " 3  3\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in sl.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module has two parameters: \n",
    "1. `centers` : controls the centers of the structure elements. \n",
    "2. `sharpness`: controls how tight the used gaussian densities are. The higher the value, the tighter. \n",
    "\n",
    "Both can be initialized using the `centers_init` resp. `sharpness_init` key word arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.0000  0.0000\n",
      " 0.5000  0.5000\n",
      " 1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "Parameter containing:\n",
      " 1  1\n",
      " 2  2\n",
      " 3  3\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "centers_init = torch.Tensor([[0,0], [0.5, 0.5], [1,1]])\n",
    "sharpness_init = torch.Tensor([[1,1], [2,2], [3,3]])\n",
    "\n",
    "sl = SLayer(3, 2, centers_init=centers_init, sharpness_init=sharpness_init)\n",
    "\n",
    "print(sl.centers)\n",
    "print(sl.sharpness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest input form for `nn.SLayer` is a `list` of `torch.Tensor` objects which are \n",
    "treated as a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "#Creating a batch of multisets\n",
    "mset_1 = [[0, 0]]\n",
    "mset_2 = [[0, 0], [0, 0]]\n",
    "mset_3 = [[1, 1], [0, 0]]\n",
    "mset_4 = [[0, 0], [1, 1]]\n",
    "batch = [mset_1, mset_2, mset_3,  mset_4]\n",
    "batch = [torch.Tensor(x) for x in batch]\n",
    "output = sl(batch)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the output dimensionality is `(4, 3)` since\n",
    "we have a batch of size `4` and `3` structure elements. \n",
    "\n",
    "This means, \n",
    "`output[i, j] =` \"evaluation of structure element j on mset_i\"\n",
    "\n",
    "Lets take a look ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0000e+00  1.3534e-01  1.5230e-08\n",
      " 2.0000e+00  2.7067e-01  3.0460e-08\n",
      " 1.1353e+00  2.7067e-01  1.0000e+00\n",
      " 1.1353e+00  2.7067e-01  1.0000e+00\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe the following:**\n",
    "\n",
    "1. The j-th stucture element approximates the multiplicity function of the given input at point `sl.centers[j]`. E.g., the output of mset_1, `output[0, :]`,  is approx. `(1, 0, 0)`. \n",
    "2. `sl.sharpness[j]` controls the amount of contribution of points not exactly on `sl.centers[j]` with respect to their distance to `sl.centers[j]`. \n",
    "3. The input is interpreted as set, i.e. is permutation invariant, as mset_3 and mset_4 do not defer as multiset and also `output[2,:] == output[3, :]`. \n",
    "\n",
    "Maybe this gets clearer if we increase the sharpness of our structure elements a \"little\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  0  0\n",
      " 2  0  0\n",
      " 1  0  1\n",
      " 1  0  1\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sl = SLayer(3, 2, centers_init=centers_init, sharpness_init=10*sharpness_init)\n",
    "print(sl(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance tip:** \n",
    "`nn.SLayer` has a static method called `prepare_batch`. Here a lot of stuff is done \n",
    "which is faster on `cpu` than on `gpu` as there is looping involved. \n",
    "You can use this method in your training environment to separate batch preparation from \n",
    "the actual calculation of the output as `nn.SLayer` recognizes a prepared batch if it gets one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  0  0\n",
       " 2  0  0\n",
       " 1  0  1\n",
       " 1  0  1\n",
       "[torch.FloatTensor of size 4x3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = SLayer.prepare_batch(batch, point_dim=2)\n",
    "sl(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`nn.SLayer` is a input layer only!**\n",
    "This means you can only use `nn.SLayer` as input layer for your model as you can not \n",
    "differentiate after its input. This is also the reason why it accepts `Tensors` and *not* `Variables` as input. <br>\n",
    "A example of a model would be ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        self.slayer = SLayer(50, 2)\n",
    "        self.linear = torch.nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.slayer(input)\n",
    "        x = self.linear(x)\n",
    "        return x "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
